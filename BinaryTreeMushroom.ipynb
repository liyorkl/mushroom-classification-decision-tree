{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import queue\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(200)\n",
    "\n",
    "mushroom = pd.read_csv('data/agaricus-lepiota.data')\n",
    "\n",
    "# check for missing values that are ? in the dataset\n",
    "missing_values = mushroom.isin(['?']).sum()\n",
    "for column in list(mushroom.loc[:,]):\n",
    "    # print(mushroom[column].value_counts())\n",
    "    pass\n",
    "\n",
    "# replace values with most common in that column\n",
    "mushroom = mushroom.replace('?', 'b')\n",
    "# print(mushroom)\n",
    "\n",
    "# using 30% of data points as a training dataset\n",
    "mushroom_testing = mushroom.sample(frac=0.3, random_state=200)\n",
    "print(mushroom_testing)\n",
    "mushroom_training = mushroom.drop(mushroom_testing.index)\n",
    "print(mushroom_training)\n",
    "mushroom_testing = mushroom_testing.reset_index(drop=True)\n",
    "mushroom_training = mushroom_training.reset_index(drop=True)\n",
    "\n",
    "mushroom = mushroom_training\n",
    "print(len(mushroom))\n",
    "print(mushroom)\n",
    "features = mushroom.columns[1:]\n",
    "print(features)\n",
    "\n",
    "variable_info = {}\n",
    "\n",
    "for feature in features:\n",
    "    variable_info[feature] = mushroom[feature].unique()\n",
    "\n",
    "print(variable_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy calculation\n",
    "def entropy(num_pos, num_neg):\n",
    "    if num_pos == 0 or num_neg == 0:\n",
    "        return 0\n",
    "    p = num_pos / (num_pos + num_neg)\n",
    "    n = num_neg / (num_pos + num_neg)\n",
    "    return -(p * math.log2(p) + n * math.log2(n))\n",
    "\n",
    "# printing binary trees, with child node names no and yes\n",
    "def printTree(node, level=0):\n",
    "    if node != None:\n",
    "        printTree(node.yes, level+1)\n",
    "        print('     '* 4 * level + '-> ' + str(node))\n",
    "        printTree(node.no, level+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For binary tree approach\n",
    "\n",
    "class binary_tree_node():\n",
    "    def __init__(self, feature, value, no, yes):\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.no = no\n",
    "        self.yes = yes\n",
    "\n",
    "    def add_no(self, no):\n",
    "        self.no = no\n",
    "    \n",
    "    def add_yes(self, yes):\n",
    "        self.yes = yes\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.value == None:\n",
    "            return f\"{self.feature}\"\n",
    "        return f\"{self.feature},{self.value}\"\n",
    "\n",
    "class DecisionTreeBinary():\n",
    "\n",
    "    root = None\n",
    "\n",
    "    @staticmethod\n",
    "    def information_gain(entropy_prev, expected_entropy):\n",
    "        return entropy_prev - expected_entropy\n",
    "\n",
    "    @staticmethod\n",
    "    def expected_entropy(num_in_feature, num_pos_in_feature, num_neg_in_feature, num_not_in_feature, num_pos_not_in_feature, num_neg_not_in_feature, total):\n",
    "        return (num_in_feature/total) * entropy(num_pos_in_feature, num_neg_in_feature) + (num_not_in_feature/total) * entropy(num_pos_not_in_feature, num_neg_not_in_feature)\n",
    "\n",
    "\n",
    "    def greedy_recrusive_splitting(self, data, remaining_features):\n",
    "        Queue = queue.Queue()\n",
    "\n",
    "        split_type = 'root'\n",
    "        self.root = binary_tree_node(None, None, None, None)\n",
    "        current_node = None\n",
    "\n",
    "        Queue.put((data, split_type, None))\n",
    "        \n",
    "        while Queue.empty() == False:\n",
    "            data, split_type, current_node = Queue.get()\n",
    "            if len(data) == 0 or len(remaining_features) == 0:\n",
    "                print('No data')\n",
    "                continue\n",
    "            max_gain = 0\n",
    "            best_feature = None\n",
    "            best_split = None\n",
    "            total = len(data)\n",
    "            total_pos = len(data[data['class'] == 'e'])\n",
    "            total_neg = len(data[data['class'] == 'p'])\n",
    "            # print(total_pos, total_neg)\n",
    "            entropy_prev = entropy(total_pos, total_neg)\n",
    "            # print(entropy_prev)\n",
    "            if entropy_prev == 0:\n",
    "                if total_pos > total_neg:\n",
    "                    if split_type == 'yes':\n",
    "                        current_node.add_yes(binary_tree_node('Edible', None, None, None))\n",
    "                    else:\n",
    "                        current_node.add_no(binary_tree_node('Edible', None, None, None))\n",
    "                else:\n",
    "                    if split_type == 'yes':\n",
    "                        current_node.add_yes(binary_tree_node('Poisonous', None, None, None))\n",
    "                    else:\n",
    "                        current_node.add_no(binary_tree_node('Poisonous', None, None, None))\n",
    "                print('Entropy is 0')\n",
    "                continue\n",
    "\n",
    "            for feature in remaining_features:\n",
    "                for value in variable_info[feature]:\n",
    "                    num_in_feature = len(data[data[feature] == value])\n",
    "                    num_not_in_feature = len(data[data[feature] != value])\n",
    "                    num_pos_in_feature = len(data[(data[feature] == value) & (data['class'] == 'e')])\n",
    "                    num_neg_in_feature = len(data[(data[feature] == value) & (data['class'] == 'p')])\n",
    "                    num_pos_not_in_feature = len(data[(data[feature] != value) & (data['class'] == 'e')])\n",
    "                    num_neg_not_in_feature = len(data[(data[feature] != value) & (data['class'] == 'p')])\n",
    "                    # print(num_in_feature, num_not_in_feature, feature, value, (f\"{num_pos_in_feature}/{total_pos}\"),num_pos_in_feature/total_pos, (f\"{num_neg_in_feature}/{total_neg}\"), num_neg_in_feature/total_neg)\n",
    "                    expected_ent = DecisionTreeBinary.expected_entropy(num_in_feature, num_pos_in_feature, num_neg_in_feature, num_not_in_feature, num_pos_not_in_feature, num_neg_not_in_feature, total)\n",
    "                    # print(expected_ent)\n",
    "                    gain = DecisionTreeBinary.information_gain(entropy_prev, expected_ent)\n",
    "                    # print(gain)\n",
    "                    if gain > max_gain:\n",
    "                        max_gain = gain\n",
    "                        best_feature = feature\n",
    "                        best_split = value\n",
    "            print(best_feature, best_split, max_gain)\n",
    "            if best_feature is None:\n",
    "                continue\n",
    "            remaining_features.remove(best_feature)\n",
    "            if split_type == 'root':\n",
    "                self.root = binary_tree_node(best_feature, best_split, None, None)\n",
    "                current_node = self.root\n",
    "            elif split_type == 'yes':\n",
    "                current_node.add_yes(binary_tree_node(best_feature, best_split, None, None))\n",
    "                current_node = current_node.yes\n",
    "            else:\n",
    "                current_node.add_no(binary_tree_node(best_feature, best_split, None, None))\n",
    "                current_node = current_node.no\n",
    "            \n",
    "            Queue.put(((data[data[best_feature] == best_split]), 'yes', current_node))\n",
    "            Queue.put(((data[data[best_feature] != best_split]), 'no', current_node))\n",
    "\n",
    "\n",
    "DTB = DecisionTreeBinary()\n",
    "DTB.greedy_recrusive_splitting(mushroom, list(features))\n",
    "\n",
    "printTree(DTB.root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For binary tree approach with depth\n",
    "\n",
    "class binary_tree_node():\n",
    "    def __init__(self, feature, value, no, yes):\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.no = no\n",
    "        self.yes = yes\n",
    "\n",
    "    def add_no(self, no):\n",
    "        self.no = no\n",
    "    \n",
    "    def add_yes(self, yes):\n",
    "        self.yes = yes\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.value == None:\n",
    "            return f\"{self.feature}\"\n",
    "        return f\"{self.feature},{self.value}\"\n",
    "\n",
    "class DecisionTreeBinary():\n",
    "\n",
    "    def __init__(self, training_data_set, testing_data_set, traget_feature, pos='p', neg='n'):\n",
    "        self.root = None\n",
    "        self.data = training_data_set\n",
    "        self.test_data = testing_data_set\n",
    "        self.data_features = training_data_set.columns[1:]\n",
    "        self.feature_values = {}\n",
    "        for feature in self.data_features:\n",
    "            self.feature_values[feature] = self.data[feature].unique()\n",
    "        self.target_feature=traget_feature\n",
    "        self.feat_is_positive = pos\n",
    "        self.feat_is_negative = neg\n",
    "\n",
    "    @staticmethod\n",
    "    def information_gain(entropy_prev, expected_entropy):\n",
    "        return entropy_prev - expected_entropy\n",
    "\n",
    "    @staticmethod\n",
    "    def expected_entropy(num_in_feature, num_pos_in_feature, num_neg_in_feature, num_not_in_feature, num_pos_not_in_feature, num_neg_not_in_feature, total):\n",
    "        return (num_in_feature/total) * entropy(num_pos_in_feature, num_neg_in_feature) + (num_not_in_feature/total) * entropy(num_pos_not_in_feature, num_neg_not_in_feature)\n",
    "\n",
    "\n",
    "    def train(self, max_depth=10):\n",
    "        remaining_features = list(self.data_features)\n",
    "        Queue = queue.Queue()\n",
    "\n",
    "        split_type = 'root'\n",
    "        self.root = binary_tree_node(None, None, None, None)\n",
    "        current_node = None\n",
    "        depth = 0\n",
    "\n",
    "        Queue.put((self.data, split_type, None, depth))\n",
    "\n",
    "        while Queue.empty() == False:\n",
    "            data, split_type, current_node, depth = Queue.get()\n",
    "            if depth > max_depth:\n",
    "                continue\n",
    "            if len(data) == 0 or len(remaining_features) == 0:\n",
    "                continue\n",
    "            max_gain = 0\n",
    "            best_feature = None\n",
    "            best_split = None\n",
    "            total = len(data)\n",
    "            total_pos = len(data[data[self.target_feature] == self.feat_is_positive])\n",
    "            total_neg = len(data[data[self.target_feature] == self.feat_is_negative])\n",
    "\n",
    "            entropy_prev = entropy(total_pos, total_neg)\n",
    "\n",
    "            if entropy_prev == 0:\n",
    "                if total_pos > total_neg:\n",
    "                    if split_type == 'yes':\n",
    "                        current_node.add_yes(binary_tree_node(self.feat_is_positive, None, None, None))\n",
    "                    else:\n",
    "                        current_node.add_no(binary_tree_node(self.feat_is_positive, None, None, None))\n",
    "                else:\n",
    "                    if split_type == 'yes':\n",
    "                        current_node.add_yes(binary_tree_node(self.feat_is_negative, None, None, None))\n",
    "                    else:\n",
    "                        current_node.add_no(binary_tree_node(self.feat_is_negative, None, None, None))\n",
    "                print('Entropy is 0')\n",
    "                continue\n",
    "\n",
    "            for feature in remaining_features:\n",
    "                for value in self.feature_values[feature]:\n",
    "\n",
    "                    num_in_feature = len(data[data[feature] == value])\n",
    "                    num_not_in_feature = len(data[data[feature] != value])\n",
    "                    num_pos_in_feature = len(data[(data[feature] == value) & (data[self.target_feature] == self.feat_is_positive)])\n",
    "                    num_neg_in_feature = len(data[(data[feature] == value) & (data[self.target_feature] == self.feat_is_negative)])\n",
    "                    num_pos_not_in_feature = len(data[(data[feature] != value) & (data[self.target_feature] == self.feat_is_positive)])\n",
    "                    num_neg_not_in_feature = len(data[(data[feature] != value) & (data[self.target_feature] == self.feat_is_negative)])\n",
    "\n",
    "                    expected_ent = DecisionTreeBinary.expected_entropy(num_in_feature, num_pos_in_feature, num_neg_in_feature, num_not_in_feature, num_pos_not_in_feature, num_neg_not_in_feature, total)\n",
    "\n",
    "                    gain = DecisionTreeBinary.information_gain(entropy_prev, expected_ent)\n",
    "\n",
    "                    if gain > max_gain:\n",
    "                        max_gain = gain\n",
    "                        best_feature = feature\n",
    "                        best_split = value\n",
    "\n",
    "            print(best_feature, best_split, max_gain)\n",
    "            remaining_features.remove(best_feature)\n",
    "\n",
    "            if split_type == 'root':\n",
    "                self.root = binary_tree_node(best_feature, best_split, None, None)\n",
    "                current_node = self.root\n",
    "            elif split_type == 'yes':\n",
    "                current_node.add_yes(binary_tree_node(best_feature, best_split, None, None))\n",
    "                current_node = current_node.yes\n",
    "            else:\n",
    "                current_node.add_no(binary_tree_node(best_feature, best_split, None, None))\n",
    "                current_node = current_node.no\n",
    "            \n",
    "            Queue.put(((data[data[best_feature] == best_split]), 'yes', current_node, depth+1))\n",
    "            Queue.put(((data[data[best_feature] != best_split]), 'no', current_node, depth+1))\n",
    "\n",
    "    def test_accuracy(self):\n",
    "        pass\n",
    "\n",
    "    def test_accuracy_at_depth(self):\n",
    "        pass\n",
    "        \n",
    "\n",
    "DTB = DecisionTreeBinary(mushroom_training, mushroom_testing, traget_feature='class', pos='e', neg='p')\n",
    "DTB.train(max_depth=2)\n",
    "\n",
    "printTree(DTB.root)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
