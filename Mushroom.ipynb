{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0221964c",
   "metadata": {},
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b1aad4",
   "metadata": {},
   "source": [
    "# Pre-Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c02be46",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Firstly we will need to import all required libraries for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac63806e-0a01-4b10-b2c0-efbb90397c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import queue\n",
    "import random\n",
    "\n",
    "random.seed(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3dec71",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the data in our directory, this will be different based on where you put the data file.\n",
    "\n",
    "On examining the file I see that the .data file is actually comma separated files. During this examination I also see that the data doesn't have a feature row, but there is information about which coloumn is which feature so I created a row above all the data with each feature's name\n",
    "\n",
    "### Missing data\n",
    "\n",
    "The data sheet say's that the data is missing some values and all the cells that are '?' is missing data. I need find these values and replace with the average of the column, I will use the mode of the column as the data is categorical. I found that the feature stalk-root has the missing data and the mode in that feature was 'b' - bulbous, so I replaced all the '?' with 'b'\n",
    "\n",
    "### Separating Training/Validation/Test data\n",
    "\n",
    "For making this decision tree model and optimising it, I need to be able to test the model on data it has not seen so we have to separate the testing data.\n",
    "\n",
    "The ultimate goal is to create a model based on all the data but we can't test how the model will react to unseen data if we don't have any more data to test on.\n",
    "\n",
    "The validation data will be within the training data set, this way we can split the data later for doing different splits (30/70, 90/10, 2-fold cross validation, 10-fold cross validation).\n",
    "\n",
    "After all the training/validating we will test the seperate models on the separated test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ce1c3cd-42eb-438c-8189-d10e3214582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mushroom = pd.read_csv('agaricus-lepiota.data')\n",
    "\n",
    "# check for missing values that are ? in the dataset\n",
    "missing_values = mushroom.isin(['?']).sum()\n",
    "# print(missing_values)\n",
    "for column in list(mushroom.loc[:,]):\n",
    "    # print(mushroom[column].value_counts())\n",
    "    pass\n",
    "\n",
    "# replace values with most common in that column\n",
    "mushroom = mushroom.replace('?', 'b')\n",
    "# print(mushroom)\n",
    "\n",
    "# using 30% of data points as a training dataset\n",
    "mushroom_testing = mushroom.sample(frac=0.3, random_state=200)\n",
    "# print(mushroom_testing)\n",
    "mushroom_training = mushroom.drop(mushroom_testing.index)\n",
    "# print(mushroom_training)\n",
    "\n",
    "# reset index so that loops won't get stuck and crash the program\n",
    "mushroom_testing = mushroom_testing.reset_index(drop=True)\n",
    "mushroom_training = mushroom_training.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5488f9",
   "metadata": {},
   "source": [
    "## Entropy Calculations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f45b26b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy calculation\n",
    "def entropy(num_pos, num_neg):\n",
    "    if num_pos == 0 or num_neg == 0:\n",
    "        return 0\n",
    "    p = num_pos / (num_pos + num_neg)\n",
    "    n = num_neg / (num_pos + num_neg)\n",
    "    return -(p * math.log2(p) + n * math.log2(n))\n",
    "\n",
    "\n",
    "def information_gain(entropy_prev, expected_entropy):\n",
    "    return entropy_prev - expected_entropy\n",
    "\n",
    "\n",
    "def expected_entropy(num_in_feature, num_pos_in_feature, num_neg_in_feature, num_not_in_feature, num_pos_not_in_feature, num_neg_not_in_feature, total):\n",
    "    return (num_in_feature/total) * entropy(num_pos_in_feature, num_neg_in_feature) + (num_not_in_feature/total) * entropy(num_pos_not_in_feature, num_neg_not_in_feature)\n",
    "\n",
    "# modified printing non-binary trees\n",
    "\n",
    "\n",
    "def printNonBinaryTree(node, level=0, split_type=None):\n",
    "    if node != None:\n",
    "        keys = list(node.split.keys())\n",
    "        num_of_values = len(keys)\n",
    "        for i in range(int(num_of_values/2)):\n",
    "            printNonBinaryTree(node.split[keys[i]], level+1, keys[i])\n",
    "        if split_type == None:\n",
    "            print('     ' * 4 * level + '-> ' + str(node))\n",
    "        else:\n",
    "            print('     ' * 4 * level + str(split_type) + ' -> ' + str(node))\n",
    "        for i in range(int(num_of_values - (num_of_values/2))):\n",
    "            printNonBinaryTree(\n",
    "                node.split[keys[i+int(num_of_values/2)]], level+1, keys[i+int(num_of_values/2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbff2e6",
   "metadata": {},
   "source": [
    "## Tree Nodes\n",
    "\n",
    "\n",
    "## Dataset_targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b39abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For non-binary tree approach\n",
    "\n",
    "class Decision_tree_node():\n",
    "    def __init__(self, feature):\n",
    "        self.feature = feature\n",
    "        self.split = {}\n",
    "\n",
    "    def add(self, split_name, node):\n",
    "        self.split[split_name] = node\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.feature}\"\n",
    "\n",
    "\n",
    "class Dataset_targets():\n",
    "\n",
    "    def __init__(self, target_feature, feature_positive, feature_negative):\n",
    "        self.target_feature = target_feature\n",
    "        self.feature_positive = feature_positive\n",
    "        self.feature_negative = feature_negative\n",
    "\n",
    "    def load(self):\n",
    "        return self.target_feature, self.feature_positive, self.feature_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5995746",
   "metadata": {},
   "source": [
    "# Decision Tree Model - Final Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    p -> p\n",
      "                    a -> e\n",
      "                    l -> e\n",
      "                                        k -> e\n",
      "                                        n -> e\n",
      "                                        h -> e\n",
      "                                                                                                    n -> e\n",
      "                                                                                s ->  cap-color\n",
      "                                                                                                    w -> p\n",
      "                                                            n ->  stalk-surface-below-ring\n",
      "                                                                                y -> p\n",
      "                                        w ->  gill-size\n",
      "                                                            b -> e\n",
      "                    n ->  spore-print-color\n",
      "                                        r -> p\n",
      "                                        o -> e\n",
      "                                        y -> e\n",
      "                                        b -> e\n",
      "->  odor\n",
      "                    f -> p\n",
      "                    c -> p\n",
      "                    y -> p\n",
      "                    s -> p\n",
      "5 depth tree --> Test accuracy 100.00%\n",
      "                    p -> p\n",
      "                    a -> e\n",
      "                    l -> e\n",
      "                                        k -> e\n",
      "                                        n -> e\n",
      "                                        h -> e\n",
      "                                        w -> e\n",
      "                    n ->  spore-print-color\n",
      "                                        r -> p\n",
      "                                        o -> e\n",
      "                                        y -> e\n",
      "                                        b -> e\n",
      "->  odor\n",
      "                    f -> p\n",
      "                    c -> p\n",
      "                    y -> p\n",
      "                    s -> p\n",
      "3 depth tree (with final depth prediction) --> Test accuracy 99.51%\n",
      "                    p -> p\n",
      "                    a -> e\n",
      "                    l -> e\n",
      "                                        k -> e\n",
      "                                        n -> e\n",
      "                                        h -> e\n",
      "                                        w ->  gill-size\n",
      "                    n ->  spore-print-color\n",
      "                                        r -> p\n",
      "                                        o -> e\n",
      "                                        y -> e\n",
      "                                        b -> e\n",
      "->  odor\n",
      "                    f -> p\n",
      "                    c -> p\n",
      "                    y -> p\n",
      "                    s -> p\n",
      "2 depth tree (without final depth prediction) --> Test accuracy 92.33%\n"
     ]
    }
   ],
   "source": [
    "class DecisionTree():\n",
    "\n",
    "    def __init__(self, training_data, validation_data, targets=None, predict_on_stopping_depth=True):\n",
    "        self.root = None\n",
    "        # If split is not set just use dataset as training and testing\n",
    "        self.training_data = training_data\n",
    "        self.validation_data = validation_data\n",
    "        self.data_features = training_data.columns[1:]\n",
    "        self.feature_values = {}\n",
    "        for feature in self.data_features:\n",
    "            self.feature_values[feature] = self.training_data[feature].unique()\n",
    "\n",
    "        self.target_feature, self.feat_is_positive, self.feat_is_negative = targets.load()\n",
    "        self.predict_on_stopping_depth = predict_on_stopping_depth\n",
    "        self.tree_depth = 0\n",
    "\n",
    "    def train(self, stopping_depth=1000, do_output=False):\n",
    "\n",
    "        if do_output:\n",
    "            print(f\"Training Decision Tree to depth of {stopping_depth} -->\")\n",
    "        remaining_features = list(self.data_features)\n",
    "        Queue = queue.Queue()\n",
    "\n",
    "        split_type = 'root'\n",
    "        self.root = Decision_tree_node(None)\n",
    "        current_node = None\n",
    "        depth = 0\n",
    "\n",
    "        Queue.put((self.training_data, split_type, None, depth))\n",
    "\n",
    "        while Queue.empty() == False:\n",
    "            data, split_type, current_node, depth = Queue.get()\n",
    "            if do_output:\n",
    "                print(f'depth: {depth}', end=f\":  {split_type} -> \")\n",
    "            if len(data) == 0 or len(remaining_features) == 0:\n",
    "                if do_output:\n",
    "                    print(\" everything classified\")\n",
    "                continue\n",
    "            max_gain = 0\n",
    "            best_feature = None\n",
    "            total = len(data)\n",
    "            total_pos = len(data[data[self.target_feature]\n",
    "                            == self.feat_is_positive])\n",
    "            total_neg = len(data[data[self.target_feature]\n",
    "                            == self.feat_is_negative])\n",
    "\n",
    "            entropy_prev = entropy(total_pos, total_neg)\n",
    "\n",
    "            if self.predict_on_stopping_depth:\n",
    "                if depth > stopping_depth-1:\n",
    "                    if total_pos > total_neg:\n",
    "                        current_node.add(\n",
    "                            split_type, Decision_tree_node(self.feat_is_positive))\n",
    "                    else:\n",
    "                        current_node.add(\n",
    "                            split_type, Decision_tree_node(self.feat_is_negative))\n",
    "                    if do_output:\n",
    "                        print(\" reached desired depth\")\n",
    "                    self.tree_depth = depth+1\n",
    "                    continue\n",
    "            else:\n",
    "                if depth > stopping_depth:\n",
    "                    if do_output:\n",
    "                        print(\" reached desired depth\")\n",
    "                    continue\n",
    "\n",
    "            if entropy_prev == 0:\n",
    "                if total_pos > total_neg:\n",
    "                    current_node.add(\n",
    "                        split_type, Decision_tree_node(self.feat_is_positive))\n",
    "                else:\n",
    "                    current_node.add(\n",
    "                        split_type, Decision_tree_node(self.feat_is_negative))\n",
    "                self.tree_depth = depth\n",
    "                if do_output:\n",
    "                    print(' Entropy is 0')\n",
    "                continue\n",
    "\n",
    "            for feature in remaining_features:\n",
    "                for value in self.feature_values[feature]:\n",
    "\n",
    "                    num_in_feature = len(data[data[feature] == value])\n",
    "                    num_not_in_feature = len(data[data[feature] != value])\n",
    "                    num_pos_in_feature = len(data[(data[feature] == value) & (\n",
    "                        data[self.target_feature] == self.feat_is_positive)])\n",
    "                    num_neg_in_feature = len(data[(data[feature] == value) & (\n",
    "                        data[self.target_feature] == self.feat_is_negative)])\n",
    "                    num_pos_not_in_feature = len(data[(data[feature] != value) & (\n",
    "                        data[self.target_feature] == self.feat_is_positive)])\n",
    "                    num_neg_not_in_feature = len(data[(data[feature] != value) & (\n",
    "                        data[self.target_feature] == self.feat_is_negative)])\n",
    "\n",
    "                    expected_ent = expected_entropy(num_in_feature, num_pos_in_feature, num_neg_in_feature,\n",
    "                                                    num_not_in_feature, num_pos_not_in_feature, num_neg_not_in_feature, total)\n",
    "\n",
    "                    gain = information_gain(entropy_prev, expected_ent)\n",
    "\n",
    "                    if gain > max_gain:\n",
    "                        max_gain = gain\n",
    "                        best_feature = feature\n",
    "\n",
    "            if split_type == 'root':\n",
    "                self.root = Decision_tree_node(best_feature)\n",
    "                current_node = self.root\n",
    "            else:\n",
    "                current_node.add(split_type, Decision_tree_node(best_feature))\n",
    "                current_node = current_node.split[split_type]\n",
    "\n",
    "            for value in self.feature_values[best_feature]:\n",
    "                Queue.put(((data[data[best_feature] == value]),\n",
    "                          value, current_node, depth+1))\n",
    "\n",
    "            if do_output:\n",
    "                print(best_feature, max_gain)\n",
    "            remaining_features.remove(best_feature)\n",
    "            self.tree_depth = depth\n",
    "\n",
    "        if do_output:\n",
    "            printNonBinaryTree(self.root)\n",
    "\n",
    "    def printTree(self):\n",
    "        printNonBinaryTree(self.root)\n",
    "\n",
    "    def classify_item(self, item):\n",
    "        current_node = self.root\n",
    "        while current_node != None:\n",
    "            feature = current_node.feature\n",
    "            value = item[feature]\n",
    "            if value not in list(current_node.split.keys()):\n",
    "                break\n",
    "            current_node = current_node.split[value]\n",
    "\n",
    "            if current_node.feature == self.feat_is_positive:\n",
    "                return self.feat_is_positive\n",
    "            elif current_node.feature == self.feat_is_negative:\n",
    "                return self.feat_is_negative\n",
    "\n",
    "        # if the tree couldn't identify the item randomly select positive or negative\n",
    "        # If we did this it will skew the testing as the 50/50 prediction may get too many wrong or right based on pure chance\n",
    "        # rand_num = random.randint(0,1).\n",
    "        #\n",
    "        # if rand_num == 0:\n",
    "        #     return self.feat_is_negative\n",
    "        # else:\n",
    "        #     return self.feat_is_positive\n",
    "\n",
    "        # if the tree couldn't identify the item return 'does not know'\n",
    "        return 'dnk'\n",
    "\n",
    "    def training_accuracy_at_depth(self, depth):\n",
    "        self.train(stopping_depth=depth)\n",
    "        total = len(self.training_data)\n",
    "        correct = 0\n",
    "        training_test_answers = self.training_data.loc[:, [\n",
    "            self.target_feature]]\n",
    "        predictions = []\n",
    "        train_data_test = self.training_data.drop(self.target_feature, axis=1)\n",
    "        for i in range(len(train_data_test)):\n",
    "            item = train_data_test.loc[i]\n",
    "            predictions.append(self.classify_item(item))\n",
    "        for i in range(total):\n",
    "            if training_test_answers.iloc[i, 0] == predictions[i]:\n",
    "                correct += 1\n",
    "        return correct/total\n",
    "\n",
    "    def validate(self):\n",
    "        if self.tree_depth == 0:\n",
    "            print(\"Train the tree first before you validate\")\n",
    "            return\n",
    "        predictions = []\n",
    "        validation_data = self.validation_data.drop(\n",
    "            self.target_feature, axis=1)\n",
    "        for i in range(len(validation_data)):\n",
    "            item = validation_data.loc[i]\n",
    "            predictions.append(self.classify_item(item))\n",
    "        return predictions\n",
    "\n",
    "    def validation_accuracy(self):\n",
    "        if self.tree_depth == 0:\n",
    "            print(\"Train the tree first before you validate\")\n",
    "            return\n",
    "        test_answers = self.validation_data.loc[:, [self.target_feature]]\n",
    "        total = len(test_answers)\n",
    "        correct = 0\n",
    "        test_predictions = self.validate()\n",
    "        for i in range(total):\n",
    "            if test_answers.iloc[i, 0] == test_predictions[i]:\n",
    "                correct += 1\n",
    "        return correct, total\n",
    "\n",
    "    def validation_error(self):\n",
    "        return 1-self.validation_accuracy()\n",
    "\n",
    "    def validation_accuracy_at_depth(self, depth, do_output=False):\n",
    "        if self.tree_depth != depth:\n",
    "            # print(f\"re-training tree to depth {depth}\")\n",
    "            self.train(stopping_depth=depth)\n",
    "        correct, total = self.validation_accuracy()\n",
    "        if do_output:\n",
    "            print(\n",
    "                f'Validation accuracy: {correct}/{total} -> {(correct/total)*100:.2f}%\\n')\n",
    "        return correct/total\n",
    "\n",
    "    def testing_accuracy_at_depth(self, depth=1000, testing_data=[]):\n",
    "        if len(testing_data) == 0:\n",
    "            raise ValueError(\"No testing data\")\n",
    "        if self.tree_depth != depth:\n",
    "            # print(f\"re-training tree to depth {depth}\")\n",
    "            self.train(stopping_depth=depth)\n",
    "        total = len(testing_data)\n",
    "        correct = 0\n",
    "        test_answers = testing_data.loc[:, [self.target_feature]]\n",
    "        predictions = []\n",
    "        testing_data = testing_data.drop(self.target_feature, axis=1)\n",
    "        for i in range(len(testing_data)):\n",
    "            item = testing_data.loc[i]\n",
    "            predictions.append(self.classify_item(item))\n",
    "        for i in range(total):\n",
    "            if test_answers.iloc[i, 0] == predictions[i]:\n",
    "                correct += 1\n",
    "        return correct/total\n",
    "\n",
    "\n",
    "mushroom_targets = Dataset_targets(\n",
    "    target_feature='class', feature_positive='e', feature_negative='p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e67fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTree(mushroom_training, mushroom_training,\n",
    "                  mushroom_targets, predict_on_stopping_depth=True)\n",
    "dt.train()\n",
    "dt.printTree()\n",
    "print(f'{dt.tree_depth} depth tree --> Test accuracy {dt.testing_accuracy_at_depth(depth=dt.tree_depth, testing_data=mushroom_testing)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2675312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt2 = DecisionTree(mushroom_training, mushroom_training,\n",
    "                   mushroom_targets, predict_on_stopping_depth=False)\n",
    "dt2.train(2)\n",
    "dt2.printTree()\n",
    "print(f'{dt2.tree_depth} depth tree (without final depth prediction) --> Test accuracy {dt2.testing_accuracy_at_depth(depth=dt2.tree_depth, testing_data=mushroom_testing)*100:.2f}%')\n",
    "\n",
    "dt3 = DecisionTree(mushroom_training, mushroom_training,\n",
    "                   mushroom_targets, predict_on_stopping_depth=True)\n",
    "dt3.train(2)\n",
    "dt3.printTree()\n",
    "print(f'{dt3.tree_depth} depth tree (with final depth prediction) --> Test accuracy {dt3.testing_accuracy_at_depth(depth=dt3.tree_depth, testing_data=mushroom_testing)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb4a11b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 2-fold cross-validation at depth 1\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.5562587904360057\n",
      "Fold 2: Validation Accuracy --> 0.5747449876890609\n",
      "Overall Validation Accuracy = 0.5655018890625333\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 3-fold cross-validation at depth 1\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.5385021097046413\n",
      "Fold 2: Validation Accuracy --> 0.5909810126582279\n",
      "Fold 3: Validation Accuracy --> 0.5730114760585675\n",
      "Overall Validation Accuracy = 0.5674981994738122\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 4-fold cross-validation at depth 1\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.5541490857946554\n",
      "Fold 2: Validation Accuracy --> 0.5947467166979362\n",
      "Fold 3: Validation Accuracy --> 0.5725\n",
      "Fold 4: Validation Accuracy --> 0.5568987077949146\n",
      "Overall Validation Accuracy = 0.5695736275718766\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 5-fold cross-validation at depth 1\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.5479331574318381\n",
      "Fold 2: Validation Accuracy --> 0.567032967032967\n",
      "Fold 3: Validation Accuracy --> 0.5521978021978022\n",
      "Fold 4: Validation Accuracy --> 0.5824742268041238\n",
      "Fold 5: Validation Accuracy --> 0.5733905579399141\n",
      "Overall Validation Accuracy = 0.564605742281329\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 6-fold cross-validation at depth 1\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.5443037974683544\n",
      "Fold 2: Validation Accuracy --> 0.5708860759493671\n",
      "Fold 3: Validation Accuracy --> 0.5683890577507599\n",
      "Fold 4: Validation Accuracy --> 0.5948905109489051\n",
      "Fold 5: Validation Accuracy --> 0.5733041575492341\n",
      "Fold 6: Validation Accuracy --> 0.562992125984252\n",
      "Overall Validation Accuracy = 0.5691276209418121\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 7-fold cross-validation at depth 1\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.5529556650246306\n",
      "Fold 2: Validation Accuracy --> 0.5244252873563219\n",
      "Fold 3: Validation Accuracy --> 0.5577889447236181\n",
      "Fold 4: Validation Accuracy --> 0.607421875\n",
      "Fold 5: Validation Accuracy --> 0.5649202733485194\n",
      "Fold 6: Validation Accuracy --> 0.5957446808510638\n",
      "Fold 7: Validation Accuracy --> 0.5702882483370288\n",
      "Overall Validation Accuracy = 0.5676492820915975\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 8-fold cross-validation at depth 1\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.5513361462728551\n",
      "Fold 2: Validation Accuracy --> 0.5643086816720257\n",
      "Fold 3: Validation Accuracy --> 0.5716911764705882\n",
      "Fold 4: Validation Accuracy --> 0.5567226890756303\n",
      "Fold 5: Validation Accuracy --> 0.5827338129496403\n",
      "Fold 6: Validation Accuracy --> 0.589041095890411\n",
      "Fold 7: Validation Accuracy --> 0.5830721003134797\n",
      "Fold 8: Validation Accuracy --> 0.5611285266457681\n",
      "Overall Validation Accuracy = 0.5700042786612998\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 9-fold cross-validation at depth 1\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.5585443037974683\n",
      "Fold 2: Validation Accuracy --> 0.5711743772241993\n",
      "Fold 3: Validation Accuracy --> 0.5470941883767535\n",
      "Fold 4: Validation Accuracy --> 0.5720720720720721\n",
      "Fold 5: Validation Accuracy --> 0.5913705583756346\n",
      "Fold 6: Validation Accuracy --> 0.5555555555555556\n",
      "Fold 7: Validation Accuracy --> 0.5993589743589743\n",
      "Fold 8: Validation Accuracy --> 0.6101083032490975\n",
      "Fold 9: Validation Accuracy --> 0.5555054151624549\n",
      "Overall Validation Accuracy = 0.5734204164635789\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 10-fold cross-validation at depth 1\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.5553602811950791\n",
      "Fold 2: Validation Accuracy --> 0.548828125\n",
      "Fold 3: Validation Accuracy --> 0.579175704989154\n",
      "Fold 4: Validation Accuracy --> 0.5700483091787439\n",
      "Fold 5: Validation Accuracy --> 0.5630026809651475\n",
      "Fold 6: Validation Accuracy --> 0.5922619047619048\n",
      "Fold 7: Validation Accuracy --> 0.6059602649006622\n",
      "Fold 8: Validation Accuracy --> 0.5992647058823529\n",
      "Fold 9: Validation Accuracy --> 0.6040816326530613\n",
      "Fold 10: Validation Accuracy --> 0.5506128007262824\n",
      "Overall Validation Accuracy = 0.5768596410252388\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision tree with 50/50 split at depth 1\n",
      "-----------------------------------------------\n",
      "Validation Accuracy --> 0.5747449876890609\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision tree with 60/40 split at depth 1\n",
      "-----------------------------------------------\n",
      "Validation Accuracy --> 0.5692307692307692\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision tree with 70/30 split at depth 1\n",
      "-----------------------------------------------\n",
      "Validation Accuracy --> 0.5668229777256741\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision tree with 80/19 split at depth 1\n",
      "-----------------------------------------------\n",
      "Validation Accuracy --> 0.5664028144239226\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision tree with 90/9 split at depth 1\n",
      "-----------------------------------------------\n",
      "Validation Accuracy --> 0.5325131810193322\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 2-fold cross-validation at depth 2\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9251054852320675\n",
      "Fold 2: Validation Accuracy --> 0.9212099894477664\n",
      "Overall Validation Accuracy = 0.9231577373399169\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 3-fold cross-validation at depth 2\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9214135021097046\n",
      "Fold 2: Validation Accuracy --> 0.9256329113924051\n",
      "Fold 3: Validation Accuracy --> 0.923229125445192\n",
      "Overall Validation Accuracy = 0.9234251796491005\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 4-fold cross-validation at depth 2\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9247538677918424\n",
      "Fold 2: Validation Accuracy --> 0.9427767354596623\n",
      "Fold 3: Validation Accuracy --> 0.92125\n",
      "Fold 4: Validation Accuracy --> 0.9141308878699458\n",
      "Overall Validation Accuracy = 0.9257278727803626\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 5-fold cross-validation at depth 2\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9217238346525946\n",
      "Fold 2: Validation Accuracy --> 0.9186813186813186\n",
      "Fold 3: Validation Accuracy --> 0.9203296703296703\n",
      "Fold 4: Validation Accuracy --> 0.929553264604811\n",
      "Fold 5: Validation Accuracy --> 0.924892703862661\n",
      "Overall Validation Accuracy = 0.9230361584262111\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 6-fold cross-validation at depth 2\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.919831223628692\n",
      "Fold 2: Validation Accuracy --> 0.9215189873417722\n",
      "Fold 3: Validation Accuracy --> 0.9361702127659575\n",
      "Fold 4: Validation Accuracy --> 0.9306569343065694\n",
      "Fold 5: Validation Accuracy --> 0.9146608315098468\n",
      "Fold 6: Validation Accuracy --> 0.9212598425196851\n",
      "Overall Validation Accuracy = 0.9240163386787538\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 7-fold cross-validation at depth 2\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9224137931034483\n",
      "Fold 2: Validation Accuracy --> 0.9008620689655172\n",
      "Fold 3: Validation Accuracy --> 0.9363484087102177\n",
      "Fold 4: Validation Accuracy --> 0.935546875\n",
      "Fold 5: Validation Accuracy --> 0.9157175398633257\n",
      "Fold 6: Validation Accuracy --> 0.9414893617021277\n",
      "Fold 7: Validation Accuracy --> 0.9223946784922394\n",
      "Overall Validation Accuracy = 0.9249675322624109\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 8-fold cross-validation at depth 2\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.919831223628692\n",
      "Fold 2: Validation Accuracy --> 0.932475884244373\n",
      "Fold 3: Validation Accuracy --> 0.9246323529411765\n",
      "Fold 4: Validation Accuracy --> 0.9180672268907563\n",
      "Fold 5: Validation Accuracy --> 0.9184652278177458\n",
      "Fold 6: Validation Accuracy --> 0.9232876712328767\n",
      "Fold 7: Validation Accuracy --> 0.9090909090909091\n",
      "Fold 8: Validation Accuracy --> 0.9252127183161666\n",
      "Overall Validation Accuracy = 0.921382901770337\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 9-fold cross-validation at depth 2\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9177215189873418\n",
      "Fold 2: Validation Accuracy --> 0.9181494661921709\n",
      "Fold 3: Validation Accuracy --> 0.9258517034068137\n",
      "Fold 4: Validation Accuracy --> 0.9256756756756757\n",
      "Fold 5: Validation Accuracy --> 0.9263959390862944\n",
      "Fold 6: Validation Accuracy --> 0.9344729344729344\n",
      "Fold 7: Validation Accuracy --> 0.9262820512820513\n",
      "Fold 8: Validation Accuracy --> 0.9061371841155235\n",
      "Fold 9: Validation Accuracy --> 0.924187725631769\n",
      "Overall Validation Accuracy = 0.9227637998722861\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 10-fold cross-validation at depth 2\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9156414762741653\n",
      "Fold 2: Validation Accuracy --> 0.91796875\n",
      "Fold 3: Validation Accuracy --> 0.9262472885032538\n",
      "Fold 4: Validation Accuracy --> 0.9033816425120773\n",
      "Fold 5: Validation Accuracy --> 0.9249329758713136\n",
      "Fold 6: Validation Accuracy --> 0.9434523809523809\n",
      "Fold 7: Validation Accuracy --> 0.9304635761589404\n",
      "Fold 8: Validation Accuracy --> 0.9411764705882353\n",
      "Fold 9: Validation Accuracy --> 0.9142857142857143\n",
      "Fold 10: Validation Accuracy --> 0.9237403540626419\n",
      "Overall Validation Accuracy = 0.9241290629208724\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision tree with 50/50 split at depth 2\n",
      "-----------------------------------------------\n",
      "Validation Accuracy --> 0.9212099894477664\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision tree with 60/40 split at depth 2\n",
      "-----------------------------------------------\n",
      "Validation Accuracy --> 0.9204395604395604\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision tree with 70/30 split at depth 2\n",
      "-----------------------------------------------\n",
      "Validation Accuracy --> 0.9226260257913247\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision tree with 80/19 split at depth 2\n",
      "-----------------------------------------------\n",
      "Validation Accuracy --> 0.9252418645558487\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision tree with 90/9 split at depth 2\n",
      "-----------------------------------------------\n",
      "Validation Accuracy --> 0.9314586994727593\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 2-fold cross-validation at depth 3\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9880450070323488\n",
      "Fold 2: Validation Accuracy --> 0.9447766443897292\n",
      "Overall Validation Accuracy = 0.966410825711039\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 3-fold cross-validation at depth 3\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.984704641350211\n",
      "Fold 2: Validation Accuracy --> 0.9881329113924051\n",
      "Fold 3: Validation Accuracy --> 0.9461812425801346\n",
      "Overall Validation Accuracy = 0.9730062651075836\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 4-fold cross-validation at depth 3\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9873417721518988\n",
      "Fold 2: Validation Accuracy --> 0.9906191369606003\n",
      "Fold 3: Validation Accuracy --> 0.9425\n",
      "Fold 4: Validation Accuracy --> 0.9879116298457691\n",
      "Overall Validation Accuracy = 0.977093134739567\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 5-fold cross-validation at depth 3\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9868073878627969\n",
      "Fold 2: Validation Accuracy --> 0.987912087912088\n",
      "Fold 3: Validation Accuracy --> 0.9848901098901099\n",
      "Fold 4: Validation Accuracy --> 0.9914089347079038\n",
      "Fold 5: Validation Accuracy --> 0.9472103004291845\n",
      "Overall Validation Accuracy = 0.9796457641604166\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 6-fold cross-validation at depth 3\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9883966244725738\n",
      "Fold 2: Validation Accuracy --> 0.9860759493670886\n",
      "Fold 3: Validation Accuracy --> 0.9832826747720365\n",
      "Fold 4: Validation Accuracy --> 0.9872262773722628\n",
      "Fold 5: Validation Accuracy --> 0.9956236323851203\n",
      "Fold 6: Validation Accuracy --> 0.9422572178477691\n",
      "Overall Validation Accuracy = 0.9804770627028084\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 7-fold cross-validation at depth 3\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9889162561576355\n",
      "Fold 2: Validation Accuracy --> 0.9798850574712644\n",
      "Fold 3: Validation Accuracy --> 0.9916247906197655\n",
      "Fold 4: Validation Accuracy --> 0.986328125\n",
      "Fold 5: Validation Accuracy --> 0.9863325740318907\n",
      "Fold 6: Validation Accuracy --> 0.9973404255319149\n",
      "Fold 7: Validation Accuracy --> 0.9441241685144124\n",
      "Overall Validation Accuracy = 0.9820787710466977\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 8-fold cross-validation at depth 3\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9887482419127989\n",
      "Fold 2: Validation Accuracy --> 0.9437299035369775\n",
      "Fold 3: Validation Accuracy --> 0.9871323529411765\n",
      "Fold 4: Validation Accuracy --> 0.9894957983193278\n",
      "Fold 5: Validation Accuracy --> 1.0\n",
      "Fold 6: Validation Accuracy --> 0.9917808219178083\n",
      "Fold 7: Validation Accuracy --> 0.9811912225705329\n",
      "Fold 8: Validation Accuracy --> 0.9852216748768473\n",
      "Overall Validation Accuracy = 0.9834125020094335\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 9-fold cross-validation at depth 3\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9873417721518988\n",
      "Fold 2: Validation Accuracy --> 0.9875444839857651\n",
      "Fold 3: Validation Accuracy --> 0.9959919839679359\n",
      "Fold 4: Validation Accuracy --> 0.9932432432432432\n",
      "Fold 5: Validation Accuracy --> 0.9796954314720813\n",
      "Fold 6: Validation Accuracy --> 0.9886039886039886\n",
      "Fold 7: Validation Accuracy --> 0.9935897435897436\n",
      "Fold 8: Validation Accuracy --> 0.9819494584837545\n",
      "Fold 9: Validation Accuracy --> 0.9435920577617328\n",
      "Overall Validation Accuracy = 0.9835057959177936\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 10-fold cross-validation at depth 3\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9876977152899824\n",
      "Fold 2: Validation Accuracy --> 0.990234375\n",
      "Fold 3: Validation Accuracy --> 0.9913232104121475\n",
      "Fold 4: Validation Accuracy --> 0.9782608695652174\n",
      "Fold 5: Validation Accuracy --> 0.9812332439678284\n",
      "Fold 6: Validation Accuracy --> 0.9851190476190477\n",
      "Fold 7: Validation Accuracy --> 0.9966887417218543\n",
      "Fold 8: Validation Accuracy --> 0.9926470588235294\n",
      "Fold 9: Validation Accuracy --> 0.9918367346938776\n",
      "Fold 10: Validation Accuracy --> 0.9872900590104403\n",
      "Overall Validation Accuracy = 0.9882331056103926\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision tree with 50/50 split at depth 3\n",
      "-----------------------------------------------\n",
      "Validation Accuracy --> 0.9447766443897292\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision tree with 60/40 split at depth 3\n",
      "-----------------------------------------------\n",
      "Validation Accuracy --> 0.985934065934066\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision tree with 70/30 split at depth 3\n",
      "-----------------------------------------------\n",
      "Validation Accuracy --> 0.9859320046893317\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision tree with 80/19 split at depth 3\n",
      "-----------------------------------------------\n",
      "Validation Accuracy --> 0.9859278803869833\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision tree with 90/9 split at depth 3\n",
      "-----------------------------------------------\n",
      "Validation Accuracy --> 0.9912126537785588\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 2-fold cross-validation at depth 4\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9961322081575246\n",
      "Fold 2: Validation Accuracy --> 0.995779106577559\n",
      "Overall Validation Accuracy = 0.9959556573675418\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 3-fold cross-validation at depth 4\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.994198312236287\n",
      "Fold 2: Validation Accuracy --> 0.9960443037974683\n",
      "Fold 3: Validation Accuracy --> 0.9849624060150376\n",
      "Overall Validation Accuracy = 0.9917350073495976\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 4-fold cross-validation at depth 4\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9957805907172996\n",
      "Fold 2: Validation Accuracy --> 0.9953095684803002\n",
      "Fold 3: Validation Accuracy --> 0.98875\n",
      "Fold 4: Validation Accuracy --> 0.9966652771988328\n",
      "Overall Validation Accuracy = 0.9941263590991082\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 5-fold cross-validation at depth 4\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9956024626209323\n",
      "Fold 2: Validation Accuracy --> 0.9978021978021978\n",
      "Fold 3: Validation Accuracy --> 0.9972527472527473\n",
      "Fold 4: Validation Accuracy --> 0.9982817869415808\n",
      "Fold 5: Validation Accuracy --> 0.9896995708154507\n",
      "Overall Validation Accuracy = 0.9957277530865818\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 6-fold cross-validation at depth 4\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9957805907172996\n",
      "Fold 2: Validation Accuracy --> 0.9924050632911392\n",
      "Fold 3: Validation Accuracy --> 0.9954407294832827\n",
      "Fold 4: Validation Accuracy --> 0.9963503649635036\n",
      "Fold 5: Validation Accuracy --> 1.0\n",
      "Fold 6: Validation Accuracy --> 0.9846894138232721\n",
      "Overall Validation Accuracy = 0.9941110270464163\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 7-fold cross-validation at depth 4\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9975369458128078\n",
      "Fold 2: Validation Accuracy --> 0.9913793103448276\n",
      "Fold 3: Validation Accuracy --> 0.9966499162479062\n",
      "Fold 4: Validation Accuracy --> 0.99609375\n",
      "Fold 5: Validation Accuracy --> 0.9977220956719818\n",
      "Fold 6: Validation Accuracy --> 1.0\n",
      "Fold 7: Validation Accuracy --> 0.9955654101995566\n",
      "Overall Validation Accuracy = 0.99642106118244\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 8-fold cross-validation at depth 4\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9971870604781997\n",
      "Fold 2: Validation Accuracy --> 0.9839228295819936\n",
      "Fold 3: Validation Accuracy --> 0.9981617647058824\n",
      "Fold 4: Validation Accuracy --> 0.9957983193277311\n",
      "Fold 5: Validation Accuracy --> 1.0\n",
      "Fold 6: Validation Accuracy --> 0.9945205479452055\n",
      "Fold 7: Validation Accuracy --> 0.9937304075235109\n",
      "Fold 8: Validation Accuracy --> 0.9950738916256158\n",
      "Overall Validation Accuracy = 0.9947993526485174\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 9-fold cross-validation at depth 4\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9968354430379747\n",
      "Fold 2: Validation Accuracy --> 0.998220640569395\n",
      "Fold 3: Validation Accuracy --> 1.0\n",
      "Fold 4: Validation Accuracy --> 0.9954954954954955\n",
      "Fold 5: Validation Accuracy --> 0.9949238578680203\n",
      "Fold 6: Validation Accuracy --> 0.9971509971509972\n",
      "Fold 7: Validation Accuracy --> 1.0\n",
      "Fold 8: Validation Accuracy --> 0.9927797833935018\n",
      "Fold 9: Validation Accuracy --> 0.9941335740072202\n",
      "Overall Validation Accuracy = 0.9966155323914005\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "Decision trees using 10-fold cross-validation at depth 4\n",
      "-----------------------------------------------\n",
      "Fold 1: Validation Accuracy --> 0.9964850615114236\n",
      "Fold 2: Validation Accuracy --> 0.99609375\n",
      "Fold 3: Validation Accuracy --> 0.9956616052060737\n",
      "Fold 4: Validation Accuracy --> 0.9927536231884058\n",
      "Fold 5: Validation Accuracy --> 1.0\n"
     ]
    }
   ],
   "source": [
    "# Validation and testing -->\n",
    "def single_split_validation(data_set, data_targets, training_validation_split=0.5, tree_depth=1, predict_on_stopping_depth=True):\n",
    "    training_data = data_set.sample(\n",
    "        frac=training_validation_split, random_state=200)\n",
    "    validation_data = data_set.drop(training_data.index)\n",
    "    training_data = training_data.reset_index(drop=True)\n",
    "    validation_data = validation_data.reset_index(drop=True)\n",
    "    print(\"\\n-----------------------------------------------\")\n",
    "    print(\n",
    "        f\"Decision tree with {int(training_validation_split*100)}/{int((1-training_validation_split)*100)} split at depth {tree_depth}\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "    dt = DecisionTree(training_data=training_data, validation_data=validation_data,\n",
    "                      targets=data_targets, predict_on_stopping_depth=predict_on_stopping_depth)\n",
    "    validation_accuracy = dt.validation_accuracy_at_depth(tree_depth)\n",
    "    print(f'Validation Accuracy --> {validation_accuracy}')\n",
    "    print(\"-----------------------------------------------\\n\")\n",
    "\n",
    "    return validation_accuracy\n",
    "\n",
    "\n",
    "def cross_validation(data_set, data_targets, folds=2, tree_depth=1, predict_on_stopping_depth=True):\n",
    "    fold_frac = 1/folds\n",
    "    data_folds = []\n",
    "    validation_accuracies = []\n",
    "    all_data = data_set\n",
    "    rest_of_data = data_set\n",
    "    for i in range(folds):\n",
    "        if i == folds-1:\n",
    "            data_folds.append(rest_of_data)\n",
    "        else:\n",
    "            data_fold = rest_of_data.sample(frac=fold_frac, random_state=200)\n",
    "            rest_of_data = rest_of_data.drop(data_fold.index)\n",
    "            data_folds.append(data_fold)\n",
    "    print(\"\\n-----------------------------------------------\")\n",
    "    print(\n",
    "        f\"Decision trees using {folds}-fold cross-validation at depth {tree_depth}\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "    for i in range(folds):\n",
    "        validation_data = data_folds[i]\n",
    "        training_data = all_data.drop(validation_data.index)\n",
    "        training_data = training_data.reset_index(drop=True)\n",
    "        validation_data = validation_data.reset_index(drop=True)\n",
    "\n",
    "        dt = DecisionTree(training_data=training_data, validation_data=validation_data,\n",
    "                          targets=data_targets, predict_on_stopping_depth=predict_on_stopping_depth)\n",
    "        validation_accuracies.append(\n",
    "            dt.validation_accuracy_at_depth(tree_depth))\n",
    "        print(\n",
    "            f'Fold {i+1}: Validation Accuracy --> {validation_accuracies[i]}')\n",
    "    print(f'Overall Validation Accuracy = {sum(validation_accuracies)/folds}')\n",
    "    print(\"-----------------------------------------------\\n\")\n",
    "\n",
    "    return sum(validation_accuracies)/folds\n",
    "\n",
    "\n",
    "def leave_one_out(data_set, data_targets, tree_depth=1, predict_on_stopping_depth=False):\n",
    "    folds = len(data_set)-1\n",
    "    return cross_validation(data_set=data_set, data_targets=data_targets, folds=folds, tree_depth=tree_depth, predict_on_stopping_depth=predict_on_stopping_depth)\n",
    "\n",
    "\n",
    "def find_best_hyper_parameters(data_set, data_targets, max_depth=10, predict_on_stopping_depth=True):\n",
    "    decision_tree_accuracies = {}\n",
    "    for depth in range(1, max_depth+1):\n",
    "        for folds in range(2, 11):\n",
    "            decision_tree_name = f'cross_validation_tree_depth_of_{depth}_with_{folds}_folds'\n",
    "            decision_tree_accuracies[decision_tree_name] = cross_validation(\n",
    "                data_set=data_set, data_targets=data_targets, folds=folds, tree_depth=depth, predict_on_stopping_depth=predict_on_stopping_depth)\n",
    "        for training_validation_split in range(50, 91, 10):\n",
    "            decision_tree_name = f'single_tree_depth_of_{depth}_training_validation_split_of_{training_validation_split:.2f}'\n",
    "            decision_tree_accuracies[decision_tree_name] = single_split_validation(data_set=data_set, data_targets=data_targets, training_validation_split=(\n",
    "                training_validation_split/100), tree_depth=depth, predict_on_stopping_depth=predict_on_stopping_depth)\n",
    "    for decision_tree_name in decision_tree_accuracies:\n",
    "        best = 0\n",
    "        if decision_tree_accuracies[decision_tree_name] > best:\n",
    "            best = decision_tree_accuracies[decision_tree_name]\n",
    "            best_decision_tree = decision_tree_name\n",
    "    print(f'{best_decision_tree} has the best accuracy of {best}')\n",
    "\n",
    "# # Tree depth 1\n",
    "# single_split_validation(mushroom_training, mushroom_targets,\n",
    "#                         training_validation_split=0.7, tree_depth=1)\n",
    "# cross_validation(mushroom_training, mushroom_targets,\n",
    "#                  mushroom_testing, folds=10, tree_depth=1)\n",
    "\n",
    "# # Tree depth 2\n",
    "# single_split_validation(mushroom_training, mushroom_targets,\n",
    "#                         training_validation_split=0.7, tree_depth=2)\n",
    "# cross_validation(mushroom_training, mushroom_targets,\n",
    "#                  folds=10, tree_depth=2)\n",
    "\n",
    "# # Tree depth 3\n",
    "# single_split_validation(mushroom_training, mushroom_targets,\n",
    "#                         training_validation_split=0.7, tree_depth=3)\n",
    "# cross_validation(mushroom_training, mushroom_targets,\n",
    "#                  folds=10, tree_depth=3)\n",
    "\n",
    "# # Tree depth 4\n",
    "# single_split_validation(mushroom_training, mushroom_targets,\n",
    "#                         training_validation_split=0.7, tree_depth=4)\n",
    "# cross_validation(mushroom_training, mushroom_targets,\n",
    "#                  folds=10, tree_depth=4)\n",
    "\n",
    "# # Tree depth 5\n",
    "# single_split_validation(mushroom_training, mushroom_targets,\n",
    "#                         mushroom_testing, training_validation_split=0.7, tree_depth=5)\n",
    "# cross_validation(mushroom_training, mushroom_targets,\n",
    "#                  folds=10, tree_depth=5)\n",
    "\n",
    "# Leave one out takes way too long for the entire dataset\n",
    "# leave_one_out(mushroom, mushroom_targets)\n",
    "\n",
    "\n",
    "find_best_hyper_parameters(data_set=mushroom_training,\n",
    "                           data_targets=mushroom_targets, max_depth=4, predict_on_stopping_depth=False)\n",
    "find_best_hyper_parameters(data_set=mushroom_training,\n",
    "                           data_targets=mushroom_targets, max_depth=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
